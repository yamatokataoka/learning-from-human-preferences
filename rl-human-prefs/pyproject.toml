[tool.poetry]
name = "rl-human-prefs"
version = "0.1.0"
description = "Replication of Deep Reinforcement Learning from Human Preferences (Christiano et al, 2017)."
license = "MIT"
authors = ["Yamato Kataoka"] 
readme = "README.md"
homepage = "https://github.com/yamatokataoka/learning-from-human-preferences"
repository = "https://github.com/yamatokataoka/learning-from-human-preferences"
keywords = ["rl-human-prefs", "reinforcement learning", "deep learning", "pytorch", "AI safety"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Education",
    "Intended Audience :: Science/Research",
    "Programming Language :: Python :: 3",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries"
]

[tool.poetry.dependencies]
python = "^3.7"

[tool.poetry.dev-dependencies]
tox = "^3.24.5"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
